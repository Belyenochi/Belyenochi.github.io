<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>从零开始的编译原理之旅----Parser篇(零)</title>
      <link href="/2018/08/28/parser_00/"/>
      <url>/2018/08/28/parser_00/</url>
      <content type="html"><![CDATA[<h3 id="0-序言"><a href="#0-序言" class="headerlink" title="0 序言"></a>0 序言</h3><p>自从去年学了编译原理已经过去快一年了，之前的编译知识体系的构建太松散，所以我准备重新梳理一遍编译的知识脉络，但我的能力毕竟有限，非常希望有能力的读者能指正我文章中的一些不足之处，编程之道，编译之路也才刚刚起步，能力有限之处也请大家多包涵。</p><h3 id="1-目录"><a href="#1-目录" class="headerlink" title="1 目录"></a>1 目录</h3><p>本系列旨在学习各种parser思路及技巧，分为以下几个部分</p><ol start="0"><li><a href="https://belyenochi.github.io/2018/08/28/parser_00/#more" target="_blank" rel="noopener"> 清晨入古寺—-论世间parser为何物<strong>[本篇]</strong></a></li><li>初日照高林—-初探First集，Follow集</li><li>曲径通幽处—-预测分析表的构建</li><li>禅房花木深—-小试LL(1)</li><li>山光悦鸟性—-再看LR(K)</li><li>潭影空人心—-浅谈SLR，LALR(1)</li><li>万籁此俱寂—-parser grammar</li><li>但余钟磬音—-反思与总结</li></ol><h3 id="2-论世间parser为何物"><a href="#2-论世间parser为何物" class="headerlink" title="2 论世间parser为何物"></a>2 论世间parser为何物</h3><p>以下为王垠前辈原文的科普，Reference会提及建议大家读一读，说起来自己入了PL的坑还是看垠神的博客开始的。</p><p>首先来科普一下。所谓parser，一般是指把某种格式的文本（字符串）转换成某种数据结构的过程。最常见的parser，是把程序文本转换成编译器内部的一种叫做“抽象语法树”（AST）的数据结构。也有简单一些的parser，用于处理CSV，JSON，XML之类的格式。</p><p>举个例子，一个处理算数表达式的parser，可以把“1+2”这样的，含有1，+，2三个字符的字符串，转换成一个对象（object）。这个对象就像new BinaryExpression(ADD, new Number(1), new Number(2))这样的Java构造函数调用生成出来的那样。</p><p>之所以需要做这种从字符串到数据结构的转换，是因为编译器是无法直接操作“1+2”这样的字符串的。实际上，代码的本质根本就不是字符串，它本来就是一个具有复杂拓扑的数据结构，就像电路一样。“1+2”这个字符串只是对这种数据结构的一种“编码”，就像ZIP或者JPEG只是对它们压缩的数据的编码一样。</p><p>这种编码可以方便你把代码存到磁盘上，方便你用文本编辑器来修改它们，然而你必须知道，文本并不是代码本身。所以从磁盘读取了文本之后，你必须先“解码”，才能方便地操作代码的数据结构。比如，如果上面的Java代码生成的AST节点叫node，你就可以用node.operator来访问ADD，用node.left来访问1，node.right来访问2。这是很方便的。</p><p>对于程序语言，这种解码的动作就叫做parsing，用于解码的那段代码就叫做parser。</p><h3 id="3-为什么需要parser"><a href="#3-为什么需要parser" class="headerlink" title="3 为什么需要parser"></a>3 为什么需要parser</h3><p>正如上文中王垠说的，程序的运行其实是在不同的数据结构之间做转换，写过Web application的同学肯定对JSON，XML这类数据格式很熟悉，那么传输过程中经常涉及到将系统中的某种数据结构parser到某种传输格式上，包括很多时候从I/O中提取数据也是个parser的过程，只不过这些parser确实比较简单，但确实是日常生活工作中不可或缺的部分，而在编译过程中其实parser就体现了将程序从高人类可读性（比如字符串）转换成高机器可读性（AST）（这里的高机器可读和VMtranslator，汇编器，指令集没有直接关系，只是为了描述高度结构化的AST可以使代码生成更加容易，也就是编译过程友好），而没有parser就意味着手写AST这个过程对于大部分人来说并不是那么直观，不过这确实对于Lisp家族程序员是一件非常美妙的事情，S-Expression万岁~</p><h3 id="4-如何使用parser"><a href="#4-如何使用parser" class="headerlink" title="4 如何使用parser"></a>4 如何使用parser</h3><ol><li>定义好一组文法（CFG等）</li><li>构建好预测表并选择对应能够解析该文法的算法（LL(1)等）<font color="red">【可选】</font>（可以使用yacc，Bison等解析）</li><li>将输入数据读入paser<font color="red">【可选】</font>（可以手写tokenizer，也可以使用Lex生成）</li></ol><p>此时得到了另一种数据结构，在编译中往往是结构化的AST，当然也可以是XML或者JSON,接&gt;下来就是应用这种数据结构的事了。</p><h3 id="5-parser图解"><a href="#5-parser图解" class="headerlink" title="5 parser图解"></a>5 parser图解</h3><p>由ohm.js生成的AST结构，将1+2*3映射到AST，便于大家感性理解<br><img src="/images/parser_00/example.jpg" alt=""></p><h3 id="6-Reference"><a href="#6-Reference" class="headerlink" title="6 Reference"></a>6 Reference</h3><p><a href="https://github.com/harc/ohm" title="ohm.js" target="_blank" rel="noopener">ohm.js</a><br><a href="https://www.quora.com/What-exactly-does-parsing-mean-in-programming" title="What-exactly-does-parsing-mean-in-programming" target="_blank" rel="noopener">What-exactly-does-parsing-mean-in-programming</a><br><a href="http://www.yinwang.org/blog-cn/2015/09/19/parser" title="王垠前辈----对parser的误解" target="_blank" rel="noopener">王垠前辈—-对parser的误解</a></p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>从零开始的正则引擎之旅(零)</title>
      <link href="/2018/08/27/regex-engine-00/"/>
      <url>/2018/08/27/regex-engine-00/</url>
      <content type="html"><![CDATA[<h3 id="1-序言"><a href="#1-序言" class="headerlink" title="1 序言"></a>1 序言</h3><p>距离挖这个坑已经过去3个月了，嗯，我没记错的的话4个月前我还挖了一个brainfuck解释器的坑，就作为下周的作业吧~<br>废话不多说，本系列旨在</p><ol><li>理解掌握一个简单parser的所作所为。</li><li>梳理正则引擎构建和优化过程中的各种该算法</li><li>造出一个能用的正则引擎（C++）</li><li>将该正则引擎作为Node.js的C++扩展</li></ol><h3 id="2-阶段构建图"><a href="#2-阶段构建图" class="headerlink" title="2 阶段构建图"></a>2 阶段构建图</h3><p><img src="/images/regex_engine_00/milestone.jpg" alt=""></p><ol><li>实现一个LL(1)的递归下降parser解析regex文法</li><li>将part1生成的AST转化为NFA</li><li>将NFA转化为DFA</li><li>优化DFA，最小化等</li><li><strong>【英雄难度副本】</strong>parser到VM code执行</li><li><strong>【史诗难度副本】</strong>采用JIT优化引擎<br>后两个阶段我现在并没有很大的把握做好，但我会尽力而为的，也欢迎熟悉这一块的同学能够给予我一些建议与指正，感激不尽。</li></ol><h3 id="3-Reference"><a href="#3-Reference" class="headerlink" title="3 Reference"></a>3 Reference</h3><p><a href="https://swtch.com/~rsc/regexp/" title="Implementing Regular Expressions Russ Cox " target="_blank" rel="noopener">Implementing Regular Expressions Russ Cox </a><br><a href="https://github.com/miura1729/ytljit/blob/master/sample/regexp.rb" title="ytljit" target="_blank" rel="noopener">ytljit</a><br><a href="https://www.zhihu.com/question/27434493" title="如何从零写一个正则表达式引擎？" target="_blank" rel="noopener">如何从零写一个正则表达式引擎？</a><br><a href="https://en.wikipedia.org/wiki/Comparison_of_regular_expression_engines" title="Comparison of regular expression engines" target="_blank" rel="noopener">Comparison of regular expression engines</a><br><a href="https://swtch.com/~rsc/regexp/regexp1.html" title="Regular Expression Matching Can Be Simple And Fast " target="_blank" rel="noopener">Regular Expression Matching Can Be Simple And Fast </a></p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>计算的要素-第六章小结</title>
      <link href="/2018/08/27/jsys_06_summary/"/>
      <url>/2018/08/27/jsys_06_summary/</url>
      <content type="html"><![CDATA[<p><em>What’s in a name?That which we call a rose by any other name would smell as sweet</em></p><p>经历了前五个小节的学习，我们终于从硬件脱身了，请让我松一口气，毕竟熟悉各种各样的硬件细节可不是我的爱好…<br>好了，现在硬件对于我们来说就是一层抽象了，工程上的优势体现了出来，抽象屏蔽使得我们在写内存管理的时候不用去思考电信号:)<br>接下来我会总结一些关于第六章汇编器的知识，然后尽力的额外扩充一些知识，以后”有时间”去填坑</p><h3 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h3><h4 id="1-1-机器语言"><a href="#1-1-机器语言" class="headerlink" title="1.1 机器语言"></a>1.1 机器语言</h4><p>机器语言分为两类，一类称作符号型（symbolic）和二进制型（binary），当然硬件实际执行的指令是二进制型号，那么为什么需要符号型呢，答案很简单，因为让机器读懂指令很容易，但让程序员读懂二进制型的机器指令（特别还不是他自己写的）就很困难了，可以想象如果有成千上百条不同的指令，那么对直接读取二进制的程序员来说想必并不舒服。此时，针对硬件可执行的二进制机器语言的抽象产生了，说是抽象其实是增加了可读性，此时可以用Load代表10000000（假定指令长度8位）的前5位，这种等效替换也出现在了marco，各种设计模式中，本质是对可读性的考虑。</p><h4 id="1-2-符号解析"><a href="#1-2-符号解析" class="headerlink" title="1.2 符号解析"></a>1.2 符号解析</h4><p>利用符号表进行符号解析</p><h4 id="1-3-汇编编译器"><a href="#1-3-汇编编译器" class="headerlink" title="1.3 汇编编译器"></a>1.3 汇编编译器</h4><p>汇编编译器的输入是一串汇编命令，然后产生一串等价的二进制指令作为输出。生成的代码被加载到计算机的内存中然后被硬件执行。<font color="blue">可见，汇编编译器主要是个文本处理程序，设计目的是用来提供翻译服务。</font>编写汇编编译器的程序员必须有完整的汇编语法说明文档和相应的二进制代码。有了这样的约定（通常称为机器语言规范），就不难编写程序，让其对每个符号命令执行下面的任务（顺序无关）</p><ul><li>解析出符号命令内在的域</li><li>对每个域，产生机器语言中相应的位域</li><li>用内存单元的数字地址来替换所有的符号引用</li><li>将二进制码汇编成完整的机器指令</li></ul><h3 id="2-指令"><a href="#2-指令" class="headerlink" title="2 指令"></a>2 指令</h3><p>Hack的指令集比较IA-32的指令可以说是很简单了，hack的指令分为寻址指令（A-指令，Addressing Instruction）和计算指令（C-指令，Comput Instruction）<br><img src="/images/jsys_06/instruction.jpg" alt=""><br>A指令的作用是将value读入A寄存器，比如你要访问内存地址为12的值，步骤如下</p><ol><li>@12 // 将12这个地址值读入A寄存器</li><li>M     // M的默认行为是将A寄存器中的值作为地址访问该地址存储的值<br><img src="/images/jsys_06/memory.jpg" alt=""></li></ol><h3 id="3-符号定义"><a href="#3-符号定义" class="headerlink" title="3 符号定义"></a>3 符号定义</h3><p>符号分为3种，分别是：</p><h4 id="3-1-预定义符号"><a href="#3-1-预定义符号" class="headerlink" title="3.1 预定义符号"></a>3.1 预定义符号</h4><p>预定义符号指代的是对应的符号在数据内存中的位置（RAM）</p><h4 id="3-2-标签符号"><a href="#3-2-标签符号" class="headerlink" title="3.2 标签符号"></a>3.2 标签符号</h4><p><img src="/images/jsys_06/preDefine.jpg" alt=""><br>标签符号中符号对应的是指令内存中的位置（ROM），且每个标签只能被定义一次，可以在程序的任何地方使用，包括在定义位置之前，这让我联想到了JS的预定义，估计也是先扫了一遍符号表，这里的符号表和编译器前端parser的符号表不是一个概念，虽然都是对符号的某种映射，但汇编器的符号表更加底层，它将符号映射到地址，而parser的符号表是一种上下文环境，这个在后面总结parser的时候会再提到。</p><h4 id="3-3-变量符号"><a href="#3-3-变量符号" class="headerlink" title="3.3 变量符号"></a>3.3 变量符号</h4><p>任何出现在汇编程序中的符号Xxx，不是预定义符号或标签符号，就将他作为变量符号处理，变量符号的地址默认从RAM[16]开始逐一分配,是的你没看错，逐一分配意味着在一个程序中已经废弃的变量也会永久持有内存，在第13章我会尝试用GC来解决部分堆内存问题，但这里的分配问题应该是指令集层面的考量所以除非修改分配策略否则无解。</p><h3 id="4-Q-amp-A"><a href="#4-Q-amp-A" class="headerlink" title="4 Q&amp;A"></a>4 Q&amp;A</h3><ul><li><p><font color="red">Q：如何完成交叉汇编程序以及生成的代码如何读取.asm的文本输入以及如何维护其符号表?</font><br><strong>A：这些在这门课都没有涉及，感兴趣的同学可以学习<a href="http://www.davidsalomon.name/assem.advertis/AssemAd.html" title="Assemblers And Loaders." target="_blank" rel="noopener">Assemblers And Loaders.</a></strong></p></li><li><p><font color="red">Q：实际计算机中的汇编程序如何工作？我确信它不会使用高级语言将.asm文件转换为二进制文件……它是如何做到的呢？使用机器代码本身？</font><br><strong>A1：40年前，许多大型计算机程序仍然用汇编语言编写，因为每个字节都计算在内。例如，IBM 370型号145是IBM的第一台带有半导体内存的大型机，它的最大配置为512 千字节RAM。基本配置仅为112 KB。存储器周期速率约为3 MHz。 随着内存越来越大，速度越来越快，我们可以不再担心程序的大小，而是使用更高级别的语言来使编程更快，更不容易出错。 现代计算机的装配工几乎肯定是用高级语言编写的，很可能是’C’。例如，参见<a href="http://en.wikipedia.org/wiki/GNU_Assembler。" target="_blank" rel="noopener">http://en.wikipedia.org/wiki/GNU_Assembler。</a> </strong><br><strong>A2：与任何其他科学领域一样，计算机科学领域由众多科学家和研究者建造，每个科学家和研究者都贡献了一小部分。所以，有很多英雄。 每种编程语言，无论是低级汇编语言还是高级现代语言，都是一种抽象。抽象是由语言设计师创造的，他们是一些有想法的人。<br>为了实现抽象，即将语言从正式规范转换为实用工具，您必须能够将用该语言编写的程序翻译成我们已经知道要执行的另一种语言。根据我们希望翻译的语言的抽象级别，此翻译代理称为“编译器”，“VM翻译器”，“汇编程序”等。无论名称如何，它总是翻译一个文本文件（例如包含C代码）到另一个文本文件（例如包含汇编代码）。因为这个翻译器本质上是非常精美的文本处理程序，所以它可以用你选择的任何语言编写。<br>尽管第一个汇编程序是用机器语言编写的，但你是正确的。但是一旦实现了第一步，生成的汇编程序就可以用来翻译符号程序，所以从那时起就不再需要用二进制代码编写代码了。剩下的就是历史……“智能是制造人造物品的能力，尤其是制造工具的工具。” （Henry Bergson，1859-1941）</strong></p></li><li><p><font color="red">Q：如果实际计算机中的汇编程序本身是用机器代码编写的，那么我是否可以使用hack汇编语言本身实现“项目6”？为什么要使用高级语言？</font><br><strong>A：使用Hack汇编语言编写汇编程序的限制因素是计算机模拟器没有I / O工具来访问主机上的文件。（但各种高级语言有I/O库）对于项目6，您需要处理存储在计算机上的.ASM文件，并编写将加载到模拟器中的.HACK文件。 </strong></p></li><li><p><font color="red">Q：我理解架构以及ROM中的二进制值如何工作，但我不知道我们如何从具有机器代码（.hack）的文本文件转到ROM中的实际二进制值。 因为它是文本文件，所以每个“1”和“0”都是ASCII字符。 那么，我们如何从硬件上的ASCII转换为真正的二进制值？</font><br><strong>A：将汇编程序的输出视为另一种中间“语言”。还有另一种工具可以读取该语言并将其加载到可以执行该语言的计算机中。<br>在像PC这样的通用计算机中，可执行文件由称为加载器的操作系统的一部分加载到存储器中。在基于ROM的计算机中，使用称为ROM编程器的硬件工具来编写ROM。<br>Hack CPU Emulator上的“加载程序”命令是模拟ROM programmer。<br>汇编器输出和可执行文件之间的软件链中通常还有另一个步骤。一个连接器  结合了多个汇编目标文件  和库 创建可执行文件。为了支持链接，目标文件包含额外的信息，告诉他们需要哪些外部函数以及外部函数可以调用的函数。 </strong></p></li></ul>]]></content>
      
      
    </entry>
    
    <entry>
      <title>计算的要素第五章小结</title>
      <link href="/2018/08/04/jsys_05_summary/"/>
      <url>/2018/08/04/jsys_05_summary/</url>
      <content type="html"><![CDATA[<p><em>what I hear, I forget;     What see, I remember; What I do, I understand.</em></p><h3 id="1-回顾"><a href="#1-回顾" class="headerlink" title="1 回顾"></a>1 回顾</h3><p><img src="/images/jsys_05/00-04.jpg" alt=""><br>经过了逻辑门，触发器，寄存器，RAM,PC，ALU，取址模式，I/O内存映像的学习，我们已经学习了实现CPU的前置条件，那么让我开始开始CPU以及进一步的Hack Machine的实现吧！</p><h3 id="2-背景"><a href="#2-背景" class="headerlink" title="2 背景"></a>2 背景</h3><h4 id="2-1-存储程序"><a href="#2-1-存储程序" class="headerlink" title="2.1 存储程序"></a>2.1 存储程序</h4><p>一个由有限硬件组件构成的计算机却可以执行无限的任务队列，从交互式游戏到字处理到科学计算，这些其实都是“存储设备    （stored program）”概念的功劳。<br>存储设备的概念想当简单：计算机基于固定的硬件平台，能够执行固定的指令集。同时，这些指令能够被当作构建模块，组成任意的模块。这种思想也体现在软件工程领域中的模块化设计，将机制（提供了什么能力）和策略（如何使用这些能力）分离。正是因为这种原因才使得Intel不用开发各种各样的游戏吧：-）</p><h4 id="2-2-冯诺依曼结构"><a href="#2-2-冯诺依曼结构" class="headerlink" title="2.2 冯诺依曼结构"></a>2.2 冯诺依曼结构</h4><p>冯诺依曼体系结构的基础是一个<strong>中央处理单元</strong>（CPU），它与<strong>内存</strong>进行交互，负责从<strong>输入设备</strong>接收数据，向<strong>输出设备</strong>发送数据。<br><img src="/images/jsys_05/stored program.jpg" alt=""><br>这个体系结构的核心在于存储程序的概念：计算机内存不仅存储着要进行操作的数据，还存储着指示计算机运行的指令。</p><h3 id="3-CPU的设计与实现"><a href="#3-CPU的设计与实现" class="headerlink" title="3 CPU的设计与实现"></a>3 CPU的设计与实现</h3><h4 id="3-1-CPU的构成"><a href="#3-1-CPU的构成" class="headerlink" title="3.1 CPU的构成"></a>3.1 CPU的构成</h4><p>CPU是计算机体系的核心，负责执行已被加载到指令内存中的指令。这些指令告诉CPU去执行不同的计算，对内存进行读/写操作，以及根据条件跳转去执行程序中其他指令。CPU通过使用三个主要的硬件要素来执行任务：算术逻辑单元（ALU，Aritmetic-Logic Unit），一组寄存器（registers）和控制单元（control unit）。<br><strong>算术逻辑单元（ALU）</strong>：ALU负责执行计算机中所有底层的算术操作和逻辑操作。比如，典型的ALU可以执行的操作包括：将两个数相加；检查一个数是否为整数；在一个数据字（word）中进行位操作；等等。<br><strong>寄存器（Registers）</strong>：CPU的设计是为了能够快速地执行简单计算。为了提高它的性能，将这些和运算相关的数据暂存到某个局部存储器中是十分必要的，这远比从内存中搬进般出要好。因此，每个CPU都配有一个一组高速寄存器（Intelx86_64中的各类寄存器），每个寄存器都能保存一个独立的字<br><strong>控制单元（Contrl Unit）</strong>：计算机指令用二进制代码来表示，通常具有16、32或64位宽。在指令能够被执行之前，须对其解码，指令里面包含的信息向不同的硬件设备（ALU，寄存器，内存）发送信号，指使它们如何执行指令。指令的解码过程是通过某些<strong>控制单元</strong>（Control Unit）。这些控制单元还负责决定下一步需要取出和执行哪一条指令。</p><h4 id="3-2-CPU的执行模型"><a href="#3-2-CPU的执行模型" class="headerlink" title="3.2 CPU的执行模型"></a>3.2 CPU的执行模型</h4><p>CPU操作现在可以被描述成一个<strong>重复的循环</strong>：从内存中取 一条指令（字）：将其解码；执行该指令，取下一条指令：如此往复循环。指令的执行过程中可能包含下面的一些子任务：让ALU计算一些值，控制内部寄存器，从存储设备中读取一个字，或向存储设备中写入一个字。在执行这些任务的过程中，CPU也会计算出下一步该读取并执行哪一条指令。<br><img src="Cycle.jpg" alt=""><br>CPU的<strong>取指-执行循环</strong>（fetch-exec cycle）模型让人不禁联想到<strong>元语言循环</strong>上（eval-apply），不过后者是指称语义的实现（本质是递归求解子表达式）而前者则是一个迭代的物理模型（通过迭代求解子问题，在这里是每一条指令，两者区别从问题的规模看前者可以分解为n层，后者则是2层（在Hack Computer的CPU模型中））<br><img src="/images/jsys_05/exp and memory.jpg" alt=""></p><h4 id="3-3-eval-apply模型"><a href="#3-3-eval-apply模型" class="headerlink" title="3.3 eval-apply模型"></a>3.3 eval-apply模型</h4><p><img src="/images/jsys_05/eval-apply.jpg" alt=""><br>本质是通过将复合过程分解为原子（atom）过程来求解（当然途中可能会对求值环境产生作用）的过程。Evaluator就是另一个程序啦~，之前写过一个简单的<a href="https://github.com/Belyenochi/SchemeREPL/blob/master/js/Scheme.js" title="Scheme Evaluator" target="_blank" rel="noopener">Scheme Evaluator</a>,感兴趣的朋友可以参考实现</p><h3 id="4-图灵机（Turing-Machine）和冯诺依曼结构（von-Neumann-architecture）的大一统"><a href="#4-图灵机（Turing-Machine）和冯诺依曼结构（von-Neumann-architecture）的大一统" class="headerlink" title="4 图灵机（Turing Machine）和冯诺依曼结构（von Neumann architecture）的大一统"></a>4 图灵机（Turing Machine）和冯诺依曼结构（von Neumann architecture）的大一统</h3><p>TM和PL的初学者（比如在下）肯定会有疑问，这些抽象的东机器实非常美，但是是怎么映射到现实世界的呢，今天就以TM为例来谈一谈优雅的理论模型是如何转化到物理的取值-执行循环的（Fetch-Execute cycle）</p><h4 id="4-1-TM"><a href="#4-1-TM" class="headerlink" title="4.1 TM"></a>4.1 TM</h4><p><img src="/images/jsys_05/TM.png" alt=""><br><img src="/images/jsys_05/TM_increase.png" alt=""></p><blockquote><p>In his 1948 essay, “Intelligent Machinery”, Turing wrote that his machine consisted of:<br>…an unlimited memory capacity obtained in the form of <strong>an infinite tape</strong> marked out into squares, on each of which a symbol could be printed. At any moment there is one symbol in the machine; it is called the <strong>scanned symbol</strong>. The machine can alter the scanned symbol, and its behavior is in part determined by that symbol, but the symbols on the tape elsewhere do not affect the behavior of the machine. However, the tape can be <strong>moved back and forth </strong>through the machine, this being one of the elementary operations of the machine. Any symbol on the tape may therefore eventually have an innings.[17] (Turing 1948, p. 3[18])</p></blockquote><p>形象的定义图灵机就是由一条无限长的纸带，字符集，状态集，当前所在位置，状态转移函数。（严格的图灵机定义是由<a href="https://en.wikipedia.org/wiki/Turing_machine" title="七元组" target="_blank" rel="noopener">七元组</a>组成，但和这里的5元组在计算能力上是等价的）<br>图灵机相当于具有标准后进先出语义的双栈PDA ，通过使用一个堆栈来模拟右侧，另一个堆栈来模拟图灵机的左侧，从文法角度看TM的计算能力相当于<strong>递归可枚举</strong>文法。</p><p>Q：图灵机是当前计算机的极限了吗？<br>A：从计算模型上来看是的，实际上到现在为止还没有超出图灵机计算能力范畴的计算机出现，无论是人工神经网络还是遗传算法，“机器学习”和“人工智能”领域的算法都是确定，有穷的，也没有超出图灵机的计算范畴，当然这么多年来人类还是有尝试的，比如<a href="https://zh.wikipedia.org/wiki/%E9%A0%90%E8%A8%80%E6%A9%9F" title="Oracle machine" target="_blank" rel="noopener">Oracle machine</a></p><p>更多关于TM的内容，可以参考Reference，和我之前的blog<a href="https://blog.csdn.net/qq_36936155/article/details/79347364" title=" 理解图灵机及其边界" target="_blank" rel="noopener"> 理解图灵机及其边界</a></p><h4 id="4-2-如何统一"><a href="#4-2-如何统一" class="headerlink" title="4.2 如何统一"></a>4.2 如何统一</h4><p><img src="/images/jsys_05/compare.jpg" alt=""><br>介绍完了TM和冯诺依曼体系，是时候进行mapping了。<br>状态集合state set -&gt; state register<br>纸带tape -&gt; memory（通常意义上是RAM）<br>状态转换函数delta -&gt; 组合电路中的输出（输出至state register相当于进入了另一个状态）<br>当前所在位置current position -&gt; PC<br>字符集character set -&gt; memory中的instruction<br>实际上，取值-执行模型中从内存中取出指令，交给CPU运算然后决定下一条指令的地址（模拟了纸带头读取当前位置，并根据当前位置进行state判断，左移右移或停机），然后改变PC（对应当前所在位置发生改变），然后循环直达到Final State（对应TM中的停机）</p><font color="blue">学过数据结构的朋友会发现图灵机实际上也代表了链式存储，call by position而冯诺依曼的RAM实际上就是Vector，嗯，通过多路选择器随机访问，call by rank，这也说明了图灵机作为理论模型在实际应用中还是需要进行trade off</font><h3 id="5-Reference"><a href="#5-Reference" class="headerlink" title="5 Reference"></a>5 Reference</h3><p><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-001-structure-and-interpretation-of-computer-programs-spring-2005/lecture-notes/lecture23webhan.pdf" title="Evaluation and universal machines The Eval/Apply Cycle Examining" target="_blank" rel="noopener">Evaluation and universal machines The Eval/Apply Cycle Examining</a><br><a href="https://en.wikipedia.org/wiki/Denotational_semantics" title="Denotational_semantics" target="_blank" rel="noopener">Denotational_semantics</a><br><a href="https://en.wikipedia.org/wiki/Turing_machine" title="Turing_machine_wiki" target="_blank" rel="noopener">Turing_machine_wiki</a><br><a href="https://philosophy.stackexchange.com/questions/48865/can-computers-do-things-turing-machines-cant" title="https://philosophy.stackexchange.com/questions/48865/can-computers-do-things-turing-machines-can&#39;t" target="_blank" rel="noopener">can-computers-do-things-turing-machines-cant</a><br><a href="chrome-extension://cdonnmffkdaoajfknoeeecmchibpmkmg/static/pdf/web/viewer.html?file=http%3A%2F%2Fport70.net%2F~nsz%2Fc%2Fc%252B%252B%2Fturing.pdf" title="C++ Templates are Turing Complete" target="_blank" rel="noopener">C++ Templates are Turing Complete</a></p>]]></content>
      
      <categories>
          
          <category> 计算机体系结构 </category>
          
      </categories>
      
      
    </entry>
    
    <entry>
      <title>计算的要素-第四章小结</title>
      <link href="/2018/08/02/jsys_04_summary/"/>
      <url>/2018/08/02/jsys_04_summary/</url>
      <content type="html"><![CDATA[<p><em>Make everything as simple as possible, but bot simpler.—- 阿尔伯特 · 爱因斯坦（1879~1955）</em></p><p>本章关于Hack机器语言的细节都在书里写的很清楚，所以这里不再赘述</p><h3 id="1-register"><a href="#1-register" class="headerlink" title="1 register"></a>1 register</h3><p><img src="/images/jsys_04/register.jpg" alt=""><br><img src="/images/jsys_04/register_detail.jpg" alt=""><br>Hack Computer的register总共只有三种，除了上一章中构建的Memory register以外，分别加了CPU内的Data register和Address/data register，值得一提的是正如上图中所见，M寄存器是特指定RAM[A]所指定的Memory特定位置的存储单元，A寄存器和D寄存器的分工也很明确，A可以用来访存和存储数据，这个数据在书本和项目中的体现就是一个地址，就像指针，我在某个内存单元a中存了内存单元b的地址,如下</p><pre><code>@aA=M</code></pre><p>那么此时A寄存器的作用就是存储数据，只不过这个数据是一个地址，那么何时算存储地址呢？<br>Answer：@a的时候会a的值放入A寄存器此时就是一个地址啦~，因为在汇编器的层面像a这种variable都会对应这一个地址，比如从RAM的第16个地址开始每个存储单元（n位register）对应一个变量，那么这个第xx个地址a对应的地址值</p><h3 id="2-memory-mapping"><a href="#2-memory-mapping" class="headerlink" title="2 memory mapping"></a>2 memory mapping</h3><p>本节一个很重要的亮点就是讲清楚了内存映像（memory mapping），下面就键盘和屏幕两个外设来说明内存映像。</p><h4 id="2-1-Keyboard"><a href="#2-1-Keyboard" class="headerlink" title="2.1 Keyboard"></a>2.1 Keyboard</h4><p><img src="/images/jsys_04/keyboard.jpg" alt=""><br>从图中可以看出，当你按下键盘的那一刻，键盘中的电路选择出你现在按下的键并通过外设的数据线（无线键盘不算），将数据送入计算机对应的端口，实际上这里还触发了一个中断，CPU会根据中断类型对应有处理中断的例程（一般写在BIOS里），然后例程和读取对应端口的输入然后写到相应的内存中去，在本课程中这个阶段忽略了中断以及相应的处理。</p><h4 id="2-2-Screen"><a href="#2-2-Screen" class="headerlink" title="2.2 Screen"></a>2.2 Screen</h4><p><img src="/images/jsys_04/screen_ex.jpg" alt=""><br><img src="/images/jsys_04/screen.jpg" alt=""><br>聊完了键盘再聊聊屏幕，Hack Computer把屏幕分成了512*256个像素点，每个像素点对应存储单元中的一个比特位，这里关于Screen根据选取内存位置选取对应行列书中有详尽的描述，本质是通过修改内存中Screen设备对应的内存映像然后写入Screen设备对应的颜色存储区形成了屏幕上不断变化的效果。更多的细节可以参考下面给出的Reference，<strong>本质上外设的处理都可以基于memory mapping</strong>，包括这里没谈到的鼠标，感兴趣的同学可以玩玩MS的Spy++，利用Hook可以看到对应的鼠标事件消息实际上是基于像素的位置的移动，那么显而易见鼠标外设的内存映像就是对应处于的位置（current position）；-）。</p><h3 id="3-mmap"><a href="#3-mmap" class="headerlink" title="3 mmap"></a>3 mmap</h3><p>mmap是一个符合POSIX标准的Unix 系统调用，它将文件或设备映射到内存中。它是一种内存映射文件 I / O的方法。它实现了请求分页，因为文件内容最初不是从磁盘读取的，根本不使用物理RAM。在访问特定位置之后，以“ lazy ”方式执行来自磁盘的实际读取</p><font color="blue">联想到Linux下的mmap，我觉得有必要深入研究一下它，所以下次专门开一篇文章谈一谈这个话题 </font><h3 id="4-Reference"><a href="#4-Reference" class="headerlink" title="4 Reference"></a>4 Reference</h3><p><a href="https://en.wikipedia.org/wiki/Memory-mapped_I/O" title="memory map From Wikipedia" target="_blank" rel="noopener">memory map from Wikipedia</a><br><a href="https://en.wikipedia.org/wiki/Mmap" title="mmap from Wikipedia" target="_blank" rel="noopener">mmap from Wikipedia</a></p>]]></content>
      
      <categories>
          
          <category> 计算机体系结构 </category>
          
      </categories>
      
      
    </entry>
    
    <entry>
      <title>计算的要素-第三章小结</title>
      <link href="/2018/08/01/jsys_03_summary/"/>
      <url>/2018/08/01/jsys_03_summary/</url>
      <content type="html"><![CDATA[<p><em>It’s a poor sort of memory that only works backward.—- Lewis Carroll</em></p><h3 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h3><p><strong>时钟（Clock）</strong>：其精确的硬件实现通常基于振荡器，其在两个信号值0-1，或称“高-低电平”。两个相邻的信号上升沿称为时钟周期，时钟周期非常重要，所有的时序逻辑都是基于时钟周期的，比如写入内存（读取内存是个时序无关操作），内存值的真实修改（假设当前时钟周期进行写入内存操作）是发生在下一个时钟周期上升沿的时候，可以参见书本的多路转换DFF实现。</p><p><strong>触发器（Filp-Flops）</strong>：此项目采用DFF（Data Filp-Flops），DFF有个时钟输入，根据主时钟信号连续地交变。数据和时钟的输入使得DFF能够实现基于时间行为out（t）=in（t-1）</p><p><strong>寄存器（register）</strong>：这里的寄存器指的是广义上的存储设备，并不仅仅是通常意义上的CPU内的register，它的存储行为是out（t）=out（t-1），也就是说他能够输出他上一个时钟周期的输入，并通过Mux（多路转换器）在条件允许（load控制）时输出至输入信号，这也就说明了它为什么能够维持自身的“状态”</p><p><img src="/images/jsys_03/DFF.jpg" alt=""></p><h3 id="2-Memories"><a href="#2-Memories" class="headerlink" title="2 Memories"></a>2 Memories</h3><p>作为一个程序员，和内存打交道的时候还是很多的，所以让我们来重点看看内存这个家伙的构造。<br><img src="/images/jsys_03/memories.jpg" alt=""><br>如图3.3所示，内存可以通过将很多寄存器堆叠起来形成随机存取RAM单元来实现。随机存取内存（RAM）这个概念由此得来：在RAM上能够随机访问被选择的字而不会受限于访问顺序。也就是说，我们要求内存中的任何字（无论具体物理位置在哪里）都能以相等的速度被直接访问。</p><p><font color="red">说到这里在数据结构课上老师说的，同学们，我们的数组具有随机性啊，随机性，当时还不太清楚这个随机性到底是怎么实现的，那么现在就真相大白了，数组的随机性实际上就是指RAM的随机性（数组可以理解成在内存中连续的片断，连续很重要，实际上在编译器层面对数组的处理也是看成一段连续的内存）</font><br>那么现在让我们一起看看RAM的随机性是如何实现的；-)</p><p>注意图3.3的输入管脚有一个address，那么实际上<strong>内存是由8个16位寄存器构成的</strong>（假定），那么在address处输入的就是3位的电信号，聪明的大家已经想到了，通过3位的电信号经过DMux（多路选择器）选择出一个唯一的8位寄存器位置，比如输入010，那么第一个0代表选择了前二分之一个内存区域（以寄存器数量为单位），010-&gt;前四个中的后两个中的第一个，完美的命中了第三个寄存器位置，你看这就完成了内存寻址。。是不是没有你想的那么复杂，当然真实环境下的内存肯定比这里来的复杂，但是这里探索的是模型和原理，具体的细节欢迎大家在评论下面补充说明。</p><h3 id="3-时序芯片和逻辑芯片的比较"><a href="#3-时序芯片和逻辑芯片的比较" class="headerlink" title="3 时序芯片和逻辑芯片的比较"></a>3 时序芯片和逻辑芯片的比较</h3><p><img src="/images/jsys_03/compare.jpg" alt=""><br>前面说到的组合逻辑芯片的输出随其输入的变化而变化，而不去考虑时间。相比之下，时序结构中包含的DFF保证了它们的输出变化仅仅发生在一个时钟周期到下一个时钟周期的转换点上（比如上升沿），而不在时钟周期内。实际上，我们允许时序芯片在时钟周期之内出现不稳定的状态，但是必须保证在下一个时钟周期的起始点，其输出值是正确的</p><p><strong>时序芯片输出这种“离散化（discretization）”过程有个重要作用：它能被用来对整个计算机系统进行同步。</strong><br>假设指示ALU计算x+y，x和y分别属于距离ALU远近程度不一的RAM（远近程度说明了他们有效的电信号到达ALU的时间），那么由于他俩在不同时刻到达ALU而ALU作为一个组合逻辑毫无时序的概念，它只会不停的从输入管脚读取数据，那么在ALU的两端输入达到稳定前，它只会不断的产生垃圾值。那么如何解决这个问题呢？既然ALU会在某个时间点给出正确的输出并且达到稳定（持续的正确输出..个人理解），在此前是输出垃圾值，那么就可以将ALU的输出连接至一个时序逻辑设备，这个设备在时钟上升沿的时候读取来自ALU的输入，那么如何保证此时读取的输入是正确的呢？这就涉及到了计算机时钟的设定，规定计算机时钟周期的长度要比1个比特在计算机系统中两个物理距离最长的芯片之间传输的时间稍长。这样就<br>能在时间上保证时序芯片得到了有效的输入值（在下个时钟周期的上升沿）。</p><p>通过时序芯片    ，可以将一个个独立的硬件同步为一个协调统一的系统。（第五章小结会有后续说明）</p><h3 id="4-本章架构图"><a href="#4-本章架构图" class="headerlink" title="4 本章架构图"></a>4 本章架构图</h3><p><img src="/images/jsys_03/architecture.png" alt=""></p>]]></content>
      
      <categories>
          
          <category> 计算机体系结构 </category>
          
      </categories>
      
      
    </entry>
    
    <entry>
      <title>计算的要素-第二章小结</title>
      <link href="/2018/07/31/jsys_02_summary/"/>
      <url>/2018/07/31/jsys_02_summary/</url>
      <content type="html"><![CDATA[<p><em>Counting is the regligion of this generation, it’s hope and salvation —- Gertrude Stein(1874-1946)</em>  </p><h3 id="1-为什么采用2-补码（2’s-complement）作为计算机的编码？"><a href="#1-为什么采用2-补码（2’s-complement）作为计算机的编码？" class="headerlink" title="1 为什么采用2-补码（2’s complement）作为计算机的编码？"></a>1 为什么采用2-补码（2’s complement）作为计算机的编码？</h3><p>稍微有一点计算机基础的同学都知道负数可以用正数的补码+1表示，事实上这是非常重要的，下面总结用补码表示n-位二进制系统具有以下属性：</p><ol><li>系统能对所有2的n次方个有符号数进行编码，最大的数和最小的数分别为2的n-1次方减1和负2的n-1次方</li><li>所有正整数的编码首位都是0</li><li>所有负整数的编码首位都是1</li><li>为了通过x的编码获得-x的编码，所有最右边的0和    从左边起的第一个1保持不变，然后将剩余的位取反。等价的捷径就是，对x的所有位取反，然后再加1，<strong>这个方案更容易在硬件中实现</strong>。<br>这种表示法使得任何两个用补码表示的有符号数的加法与正数的加法完全相同，比如（1110）+（1101）=1011（丢掉溢出位），刚好等于-5，而减法被等价为x - y = x + （-y）</li></ol><h3 id="2-ALU的原理以及实现"><a href="#2-ALU的原理以及实现" class="headerlink" title="2 ALU的原理以及实现"></a>2 ALU的原理以及实现</h3><p>通过2’s complement我们可以发现现在已经可以执行几乎任何算术（加减）和逻辑（与或非多路转换等）操作了，那么这时候就需要通过封装来使用他们，实际上这又是一种通过抽象简化设计的体现，ALU从此应运而生了。<br>事实上在《计算的要素艺术中》已经对ALU的原理与实现有充分的说明，<strong>究其本质组合逻辑是对真值表的一个物理映射。</strong></p><h3 id="3-计算机系统结构的8个伟大思想"><a href="#3-计算机系统结构的8个伟大思想" class="headerlink" title="3 计算机系统结构的8个伟大思想"></a>3 计算机系统结构的8个伟大思想</h3><p>事实上，在任何计算机中，软硬件平台的整体功能都是由ALU和运行在其上的操作系统共同决定的。因此，当设计新的系统时，ALU应该实现多少功能，本质上是个性价比的问题。一般的原则是算术和逻辑操作的硬件实现成本较高，但是性能较好。（《计算的要素》中对ALU并没有实现乘除和浮点运算是对复杂度的一个权衡，对乘除和浮点运算会在软件层面给予实现），那么让我来谈谈计算机系统结构中的8个伟大思想：</p><ul><li>面向摩尔定律的设计</li><li>使用抽象简化设计</li><li>加速大概率事件</li><li>通过并行提高性能</li><li>通过流水线提高性能</li><li>通过预测提高性能</li><li>建立存储器层次</li><li>通过冗余提高可靠性（在数据库中经常出没的冗余备份等等）</li></ul><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>《计算的要素》<br>《计算机组成与设计-软件/硬件接口》</p>]]></content>
      
      <categories>
          
          <category> 计算机体系结构 </category>
          
      </categories>
      
      
    </entry>
    
    <entry>
      <title>计算的要素-第一章小结</title>
      <link href="/2018/07/30/jsys_01_summary/"/>
      <url>/2018/07/30/jsys_01_summary/</url>
      <content type="html"><![CDATA[<p><em>Such simple things,And we make of them something so complex it defeats us ,Almost. —-John Ashbery(1927)</em></p><h3 id="1-OverView"><a href="#1-OverView" class="headerlink" title="1 OverView"></a>1 OverView</h3><p><img src="/images/jsys_01/ClassOverview.jpg" alt=""><br>以上是课程的学习，内容，让我们bottum up搭建一个计算机吧!</p><h3 id="2-什么是逻辑门（logic-Gate）？"><a href="#2-什么是逻辑门（logic-Gate）？" class="headerlink" title="2 什么是逻辑门（logic Gate）？"></a>2 什么是逻辑门（logic Gate）？</h3><p>在谈论什么是逻辑门之前，我们得先谈谈布尔代数，因为计算机硬件基于二进制数据的表示和处理，所以布尔代数成了计算机中事实上不可或缺的理论根基。<br>学过离散数学的朋友肯定对真值表不陌生，事实上逻辑门就是由布尔函数的物理具象化，输入和输出就是真值表的变量，如果布尔函数f有n个输入变量，返回m个二进制的结果，那么用来实现这个函数f的门将会有n个输入管脚（input pins）和m个输出管脚（ouput pins） 。当我们把一些值从输入管脚输入，它的内部结构即逻辑门<br>会计算然后输出对应的结果值。<br><img src="/images/jsys_01/logicGate.jpg" alt=""></p><h3 id="3-如何使用逻辑门"><a href="#3-如何使用逻辑门" class="headerlink" title="3 如何使用逻辑门"></a>3 如何使用逻辑门</h3><p><img src="/images/jsys_01/implementOfGate.jpg" alt=""><br>对于任何给定的逻辑门，我们都能够从外部和内部两个不同方面进行观察，图1.4中右边的图给出了门的内部结构（或称为内部实现），而左边部分仅仅显示了门的外部接口（interface），也就是输入和输出管脚。内部结构仅仅与门电路的设计者相关，而外部结构则是其他设计者所关心的（也就是外部结构也就是我们常常使用的黑盒抽象，只关心输入输出），他们仅仅使用门电路的抽象而不去关心其内部结构。<br>下面总结两点关于逻辑设计的要素：</p><ol><li>虽然逻辑设计（门电路设计者）的基本功能可以通过不同的的方式实现其外部接口，但从效率的角度上来说，<strong>基本原则</strong>是用尽可能少的门来显示尽可能多的功能。</li><li>给定门的描述（外部接口），通过应用已经实现的门，找到有效的方法来实现它。<br><strong>因为本课程后续部分采用了HDL语言，所以这里简单的解释HDL语言：</strong><br>chips(芯片)的HDL定义包括header部分和parts部分。<br>Header部分描述了芯片的接口(interface)，也就是芯片的名称、输入和输出管脚。<br>Pars部分描述了所有底层电路的名称和拓扑结构，这些电路是构成该芯片的基本部分，每个部分用一个statement(语句)来表示，它描述了该部分的名称与其他部分的连接方式。<br>为了简单明了的编写这些语句，HDL程序员必须有内在模块的接口文档，体现在project中就是注释了。<br>形如part’s pin name = chip’s pin name的含义是将芯片内部的管脚与外部管教相连，如此实现了芯片的输入输出。<br>更多关于HDL程序设计的内容可以参考《计算的要素》附录部分。</li></ol><h3 id="4-为什么使用逻辑门"><a href="#4-为什么使用逻辑门" class="headerlink" title="4 为什么使用逻辑门"></a>4 为什么使用逻辑门</h3><p>之前曾谈到计算机的计算模型采用了布尔代数，从图灵机的纸带存储符号,到冯诺依曼体系结构的memory都采用了0,1作为数据的表示形式，其根本是高效和简单（当然lambda calculus不是这么做的，你可以自己定义数字如church numerals，函数等，因为是抽象模型所以理解和运算起来没有0，1在实际应用中直接，但事实上无论是TM,lambda calculus，冯诺依曼体系结构都是等价的，可以说前两者是等价的计算模型，后者是物理实现模型，本质都是对计算的建模且等价！）</p><h3 id="5-各种逻辑门（project中的图示）"><a href="#5-各种逻辑门（project中的图示）" class="headerlink" title="5 各种逻辑门（project中的图示）"></a>5 各种逻辑门（project中的图示）</h3><p>项目地址<a href="https://github.com/Belyenochi/nand2tetris" target="_blank" rel="noopener">https://github.com/Belyenochi/nand2tetris</a></p><ol><li>And<br><img src="/images/jsys_01/And.png" alt=""></li><li>And16<br><img src="/images/jsys_01/And16.png" alt=""></li><li>Dmux<br><img src="/images/jsys_01/DMux.png" alt=""></li><li>DMux4Way<br><img src="/images/jsys_01/DMux4Way.png" alt=""></li><li>DMux8Way<br><img src="/images/jsys_01/DMux8Way.png" alt=""></li><li>Mux<br><img src="/images/jsys_01/Mux.png" alt=""></li><li>Mux4Way16<br><img src="/images/jsys_01/Mux4Way16.png" alt=""></li><li>Not<br><img src="/images/jsys_01/Not.png" alt=""></li><li>Or<br><img src="/images/jsys_01/Or.png" alt=""></li><li>Xor<br><img src="/images/jsys_01/Xor.png" alt=""></li></ol>]]></content>
      
      <categories>
          
          <category> 计算机体系结构 </category>
          
      </categories>
      
      
    </entry>
    
  
  
</search>
